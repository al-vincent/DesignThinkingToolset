import http.client, urllib.request, urllib.parse, urllib.error
from json import loads
import matplotlib.pyplot as plt
from matplotlib.patches import Polygon
from PIL import Image
import functools
import os

def get_image_bytes(image_path):
    # Read the image into a byte array
    try:
        with open(image_path, "rb") as f:
            return f.read()
    except FileNotFoundError:
        print(f"*** ERROR: the file {image_path} was not found. ***")
        # exit(1)
        return None
    except Exception as err:
        print(f"*** ERROR: {err}")
        # exit(2)
        return None

def analyse_image(prediction_key, subscription_key, project_id, published_name, image_bytes):
    """
    Access the Azure Custom Vision service to process an image.
    
    Parameters:
        - prediction_key (str), the prediction key generated by the Custom 
        Vision service for the detection model.
        - subscription_key (str), the ID for the Azure subscription
        - project_id (str), the Custom Vision identifier for the project
        - published_name (str), the name of the published model
        - image_bytes (bytes), the image to be analysed
    
    Returns:
        - JSON-style dict containing the results of the analysis (e.g. bounding
        box coordinates of images detected, name of the tag detected, 
        probability of correct detection etc.)
    """
    
    headers = {
        # Request headers
        'Prediction-Key': prediction_key,
        'Content-Type': 'application/octet-stream',
        'Prediction-key': subscription_key
    }

    # AV: not currently used, but might be good to pass an app name at some point?
    params = urllib.parse.urlencode({
        # Request parameters
        'application': '{string}',
    })

    data = None
    try:
        conn = http.client.HTTPSConnection('uksouth.api.cognitive.microsoft.com')
        conn.request("POST", f"/customvision/v3.0/Prediction/{project_id}/detect/iterations/{published_name}/image", image_bytes, headers)
        data = conn.getresponse().read()
        conn.close()
        return loads(data.decode("utf-8"))
    except Exception as err:
        # print("[Errno {0}] {1}".format(e.errno, e.strerror))
        print(f"ERROR: {err}")
        return None

def image_transpose_exif(img):
    """
    Apply Image.transpose to ensure 0th row of pixels is at the visual
    top of the image, and 0th column is the visual left-hand side.

    As per CIPA DC-008-2012, the orientation field contains an integer,
    1 through 8. Other values are reserved.
    
    Credit: Roman Odaisky, 
    https://stackoverflow.com/questions/4228530/pil-thumbnail-is-rotating-my-image
    
    Parameters:
        - img (object), a binary stream containing the image data.
        
    Returns either the transformed image, or the original image if the 
    orientation cannot be determined.
    """

    exif_orientation_tag = 0x0112
    exif_transpose_sequences = [                   # Val  0th row  0th col
        [],                                        #  0    (reserved)
        [],                                        #  1   top      left
        [Image.FLIP_LEFT_RIGHT],                   #  2   top      right
        [Image.ROTATE_180],                        #  3   bottom   right
        [Image.FLIP_TOP_BOTTOM],                   #  4   bottom   left
        [Image.FLIP_LEFT_RIGHT, Image.ROTATE_90],  #  5   left     top
        [Image.ROTATE_270],                        #  6   right    top
        [Image.FLIP_TOP_BOTTOM, Image.ROTATE_90],  #  7   right    bottom
        [Image.ROTATE_90],                         #  8   left     bottom
    ]

    try:
        seq = exif_transpose_sequences[img._getexif()[exif_orientation_tag]]
    except Exception:
        return img
    else:
        return functools.reduce(type(img).transpose, seq, img)

def show_results(analysis, image_path, threshold=0.2):
    """
    Display the results of the image processing. The image is displayed with
    a bounding box drawn around each area that corresponds to a tag that the 
    model has been trained on.
    
    Parameters:
        - analysis (dict), the output from the Computer Vision algorithm
        - image_path (str), the filepath for the image
        - threshold (float), the lowest probability of correct ID that we wish
        to draw on the image. E.g. if threshold is set to 0.2, any results where
        the model believes that the probability is < 0.2 will be ignored.
    
    Returns None.
    """
    # check if the analysis has been successful
    if "predictions" in analysis:
        try:
            image = Image.open(image_path)
        except IOError:
            print(f"*** ERROR: the file {image_path} was not found. ***")
            exit(2)
        # get the dimensions of the image            
        width, height = image.size
        
        polygons = []    
        for line in analysis["predictions"]:
            # Extract the bounding boxes and their probability of correct ID
            bb = line["boundingBox"]
            polygons.append({
                        "vertices": [(bb["left"] * width, bb["top"] * height),
                                    ((bb["left"] + bb["width"]) * width, bb["top"] * height),
                                    ((bb["left"] + bb["width"]) * width, (bb["top"] + bb["height"]) * height),
                                    (bb["left"] * width, (bb["top"] + bb["height"]) * height)],
                        "probability": line["probability"]
                         })

        # Display the image and overlay it with the extracted text.
        plt.figure(figsize=(30, 30))
        
        # check the image orientation, and alter if necessary
        new_image = image_transpose_exif(image)
        ax = plt.imshow(new_image)
        # plot each of the display boxes
        for polygon in polygons:
            if polygon["probability"] >= threshold:
                patch = Polygon(polygon["vertices"], closed=True, fill=False, 
                                linewidth=2, color='r')
                ax.axes.add_patch(patch)
        image.close()
    else:
        print(f"*** WARNING: no text was found in {image_path}. Results: {analysis} ***")
        exit(3)

def main():
    """
    Example runner for the function 
    """
    # Azure Custom Vision parameters
    PREDICTION_KEY = os.environ.get("PREDICTION_KEY") 
    SUBSCRIPTION_KEY = os.environ.get("SUBSCRIPTION_KEY")
    PROJECT_ID = os.environ.get("PROJECT_ID") 
    PUBLISHED_NAME = os.environ.get("PUBLISHED_NAME") 

    # Image file to process
    # IMAGE_PATH = "C:/Users/Al/OneDrive/Code/DesignThinkingToolset/media/test/test_img.jpg"
    IMAGE_PATH = "C:/Users/Al/OneDrive/Pictures/PostIts/persona.jpg"
    image_bytes = get_image_bytes(IMAGE_PATH)
    image_data = analyse_image(prediction_key=PREDICTION_KEY,
                               subscription_key=SUBSCRIPTION_KEY,
                               project_id=PROJECT_ID,
                               published_name=PUBLISHED_NAME,
                               image_bytes=image_bytes)
    
    # Set the threshold, i.e. the lowest probability of 'correctness' at which 
    # images are kept.
    THRESHOLD = 0.2
    show_results(analysis=image_data, image_path=IMAGE_PATH, threshold=THRESHOLD)

if __name__ == "__main__":
    main()
